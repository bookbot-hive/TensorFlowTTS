{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-15 01:57:12.198244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/s44504/miniconda3/envs/tftts2/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-07-15 01:57:12,735 - INFO - Using tensorflow=2.12.0, onnx=1.16.1, tf2onnx=1.16.1/15c810\n",
      "2024-07-15 01:57:12,735 - INFO - Using opset <onnx, 15>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-07-15 01:57:12,800 - WARNING - Replacing scalar output shape of length_regulator/Sum_1 with unknown shape\n",
      "2024-07-15 01:57:12,801 - WARNING - Replacing scalar output shape of length_regulator/sub with unknown shape\n",
      "2024-07-15 01:57:13,009 - INFO - Optimizing ONNX model\n",
      "2024-07-15 01:57:14,227 - INFO - After optimization: Cast -100 (152->52), Concat -10 (34->24), Const -196 (432->236), DequantizeLinear -12 (82->70), DynamicQuantizeLinear -12 (25->13), Gather -9 (34->25), GlobalAveragePool +32 (0->32), Identity -3 (3->0), QuantizeLinear -1 (1->0), ReduceMean -32 (32->0), ReduceProd -19 (31->12), Reshape -39 (136->97), Shape -1 (19->18), Slice -1 (9->8), Transpose -133 (191->58), Unsqueeze -22 (60->38)\n",
      "2024-07-15 01:57:14,245 - INFO - \n",
      "2024-07-15 01:57:14,245 - INFO - Successfully converted TensorFlow model lightspeech_quant.tflite to ONNX\n",
      "2024-07-15 01:57:14,245 - INFO - Model inputs: ['input_ids', 'speaker_ids', 'speed_ratios', 'f0_ratios', 'energy_ratios']\n",
      "2024-07-15 01:57:14,245 - INFO - Model outputs: ['Identity', 'Identity_1', 'Identity_2']\n",
      "2024-07-15 01:57:14,245 - INFO - ONNX model is saved at lightspeech_quant.onnx\n",
      "2024-07-15 01:57:15.149255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/s44504/miniconda3/envs/tftts2/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2024-07-15 01:57:15,656 - INFO - Using tensorflow=2.12.0, onnx=1.16.1, tf2onnx=1.16.1/15c810\n",
      "2024-07-15 01:57:15,656 - INFO - Using opset <onnx, 15>\n",
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "INFO: TfLiteFlexDelegate delegate: 496 nodes delegated out of 580 nodes with 1 partitions.\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-07-15 01:57:16,538 - INFO - Optimizing ONNX model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-15 01:57:18,385 - INFO - After optimization: Cast -192 (218->26), Concat +4 (80->84), Const -542 (659->117), Gather +4 (9->13), Identity -108 (108->0), Reshape -80 (180->100), Split +4 (0->4), Squeeze -9 (83->74), Transpose -75 (183->108), Unsqueeze -66 (113->47)\n",
      "2024-07-15 01:57:18,412 - INFO - \n",
      "2024-07-15 01:57:18,412 - INFO - Successfully converted TensorFlow model mbmelgan.tflite to ONNX\n",
      "2024-07-15 01:57:18,412 - INFO - Model inputs: ['mels']\n",
      "2024-07-15 01:57:18,412 - INFO - Model outputs: ['Identity']\n",
      "2024-07-15 01:57:18,412 - INFO - ONNX model is saved at mbmelgan.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --tflite lightspeech_quant.tflite --output lightspeech_quant.onnx\n",
    "!python -m tf2onnx.convert --tflite mbmelgan.tflite --output mbmelgan.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_tts.inference import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"bookbot/lightspeech-mfa-sw-v2\", use_auth_token=True)\n",
    "processor.mode = \"eval\" # change processor from train to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "model_path = \"./lightspeech_quant.onnx\"\n",
    "lightspeech = ort.InferenceSession(model_path)\n",
    "\n",
    "model_path = \"./mbmelgan.onnx\"\n",
    "mbmelgan = ort.InferenceSession(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Kwa maana Mungu aliupenda ulimwengu kiasi cha kumtoa Mwanae pekee, ili kila mtu amwaminiye asipotee, bali awe na uzima wa milele.\"\n",
    "input_ids = processor.text_to_sequence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_ids = np.array([input_ids], dtype=np.int32)\n",
    "speaker_ids = np.array([0], dtype=np.int32)\n",
    "speed_ratios = np.array([1.0], dtype=np.float32)\n",
    "f0_ratios = np.array([1.0], dtype=np.float32)\n",
    "energy_ratios = np.array([1.0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "inputs = {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"speaker_ids\": speaker_ids,\n",
    "    \"speed_ratios\": speed_ratios,\n",
    "    \"f0_ratios\": f0_ratios,\n",
    "    \"energy_ratios\": energy_ratios,\n",
    "}\n",
    "\n",
    "mel_output, durations, _ = lightspeech.run(None, inputs)\n",
    "outputs = mbmelgan.run(None, {\"mels\": mel_output,})\n",
    "audio_tflite = outputs[0][0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write(\"john3.wav\", audio_tflite, 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_output.shape, audio_tflite.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
